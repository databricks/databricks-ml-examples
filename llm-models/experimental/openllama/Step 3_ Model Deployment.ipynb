{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d06c839a-4ce8-4a4b-b81b-b4fb332f59cb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install bitsandbytes\n",
    "%pip install accelerate\n",
    "%pip install git+https://github.com/huggingface/peft.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85658232-793e-4a5f-aaa9-a5c855494f53",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ffb93a5f-af44-46b9-8aff-b26090c68b61",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Replace the path names based on where the adapters, model and tokenizers were saved during your work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bd220e1-079f-4205-85d5-f87bb50ef425",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "peft_model_id = \"/dbfs/FileStore/shared_uploads/<your-user-name>/dollyllama\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99a402a1-82ca-4a35-aac8-e9e1d8e30c45",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pretrained_model_id = 'openlm-research/open_llama_7b_v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81f0d773-e4fd-4c5d-80a2-794a7a6fd435",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a79fc21e-84c7-4601-94fd-86cff1d3f8f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    pretrained_model_id, device_map='auto',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59aa8ce8-7c78-4817-923e-71042dea216a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "config.base_model_name_or_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "415fe516-d2ad-418d-ae40-b7bb554780f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "peft_model = PeftModel.from_pretrained(model, peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a3bb8e2-1c71-4adb-9f27-ebea0e91ef4e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "merged_model_path = \"/dbfs/FileStore/shared_uploads/<your-user-name>/dollyllama/merged_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "519eed8a-0335-4758-a177-222d7f76694b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "merged_model = peft_model.merge_and_unload()\n",
    "merged_model.save_pretrained(merged_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5aa1ce40-25f7-4b80-a16c-5c575aae6525",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "merged_model_tokenizer_path = \"/dbfs/FileStore/shared_uploads/<your-user-name>/dollyllama/merged_model_tokenizer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4608d2e4-0778-4ce5-b504-be35d819c3e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(merged_model_tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93f13490-853e-4194-abb8-18cdd9af1c05",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Ensure that the final model can be loaded from the saved path\n",
    "model = LlamaForCausalLM.from_pretrained(merged_model_path, torch_dtype=torch.float16).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "539319d5-939b-4e79-b1a1-9d7923c08b07",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "209746f2-2718-41da-b9c6-b22d56648b23",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Ensure that the tokenizer can be loaded from the saved path\n",
    "tokenizer = LlamaTokenizer.from_pretrained(merged_model_tokenizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32ec0054-d885-4084-91d2-432ca86645cd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Testing preprocessing and prediction functions before composing the pyfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fbfbd2b-2a4a-4ce6-9e1f-80e009c9ea20",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def build_prompt(instruction):\n",
    "    prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "  ### Instruction:\n",
    "  {}\n",
    "\n",
    "  ### Response:\n",
    "  \"\"\".format(instruction)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e095d0a1-ba3d-45a7-994e-07f086334b95",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def parse(text):\n",
    "    start_marker = '### Response:'\n",
    "    end_marker = '### End'\n",
    "    start_index = text.find(start_marker)\n",
    "    end_index = text.find(end_marker, start_index + len(start_marker))\n",
    "    \n",
    "    return (text[start_index + len(start_marker):].strip() if start_index != -1 and end_index == -1\n",
    "            else text[start_index + len(start_marker):end_index].strip() if start_index != -1\n",
    "            else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c45fda48-4213-4497-8391-973286e3b4ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def extract_response(text):\n",
    "    start_marker = '### Response:'\n",
    "    end_marker = '### End'\n",
    "    start_index = text.find(start_marker)\n",
    "    end_index = text.find(end_marker, start_index + len(start_marker))\n",
    "    \n",
    "    return (text[start_index + len(start_marker):].strip() if start_index != -1 and end_index == -1\n",
    "            else text[start_index + len(start_marker):end_index].strip() if start_index != -1\n",
    "            else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb8e99bc-dcab-4d40-88d4-79f207ae6363",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Explain how the US economy works using an analogy\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "# input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to('cuda')\n",
    "\n",
    "# generation_output = model.generate(\n",
    "#     input_ids=input_ids, max_new_tokens=128, penalty_alpha=0.5, top_k=4, \n",
    "# )\n",
    "# response = extract_response(tokenizer.decode(generation_output[0]))\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42d23fe3-1833-4e40-9158-2bc91c1c7f6f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "payload_pd = pd.DataFrame([[prompt]],columns=['text'])\n",
    "payload_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "faf8d3eb-3073-41db-81ca-4e5641dffe46",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "input_example = payload_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4873b494-2d69-4734-bec8-70f1b6ed57cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def predict(model_input):\n",
    "    import json\n",
    "    question = model_input.iloc[:,0].to_list()[0] # get the first column\n",
    "    prompt = build_prompt(question)\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to('cuda')\n",
    "    generation_output = model.generate(\n",
    "    input_ids=input_ids[\"input_ids\"], max_new_tokens=128, penalty_alpha=0.5, top_k=4)\n",
    "    output = parse(tokenizer.decode(generation_output[0]))\n",
    "    result = {'response': output}\n",
    "    return json.dumps(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be9fcc15-f72e-4d48-81ae-e176b84210bf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "predict(input_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1c43dc2-9175-439b-82d9-301d2285b8cf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Log with MLFlow and Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd6f8d7f-1825-449d-8ce2-b6edc47e267f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "artifacts = {\n",
    "\"tokenizer_path\": merged_model_tokenizer_path,\n",
    "\"model_path\": merged_model_path,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec3eed58-52a3-43e6-89b5-9541098c7b0d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow.pyfunc\n",
    "\n",
    "class Dollyllama(mlflow.pyfunc.PythonModel):\n",
    "  def load_context(self, context):\n",
    "    from transformers import AutoModelForCausalLM\n",
    "    from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "    import torch\n",
    "    self.tokenizer = LlamaTokenizer.from_pretrained(context.artifacts['tokenizer_path'])\n",
    "    self.model = LlamaForCausalLM.from_pretrained(context.artifacts['model_path'], torch_dtype=torch.bfloat16)\n",
    "    self.model.to(device = \"cuda\")\n",
    "    self.model.eval()\n",
    "\n",
    "  def build_prompt(self, instruction):\n",
    "    prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "  ### Instruction:\n",
    "  {}\n",
    "\n",
    "  ### Response:\n",
    "  \"\"\".format(instruction)\n",
    "    return prompt\n",
    "\n",
    "  def parse(self, text):\n",
    "    start_marker = '### Response:'\n",
    "    end_marker = '### End'\n",
    "    start_index = text.find(start_marker)\n",
    "    end_index = text.find(end_marker, start_index + len(start_marker))\n",
    "    \n",
    "    return (text[start_index + len(start_marker):].strip() if start_index != -1 and end_index == -1\n",
    "            else text[start_index + len(start_marker):end_index].strip() if start_index != -1\n",
    "            else None)\n",
    "\n",
    "\n",
    "  def predict(self, context, model_input):\n",
    "    import json\n",
    "    question = model_input.iloc[:,0].to_list()[0] # get the first column\n",
    "    prompt = self.build_prompt(question)\n",
    "    input_ids = self.tokenizer(prompt, return_tensors=\"pt\").to('cuda')\n",
    "    generation_output = self.model.generate(\n",
    "    input_ids=input_ids[\"input_ids\"], max_new_tokens=180, penalty_alpha=0.5, top_k=4)\n",
    "    output = self.parse(self.tokenizer.decode(generation_output[0]))\n",
    "    result = {'response': output}\n",
    "    return json.dumps(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59de718a-13a5-4149-845e-cc7910e9b3de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sys import version_info\n",
    " \n",
    "PYTHON_VERSION = \"{major}.{minor}.{micro}\".format(major=version_info.major,\n",
    "                                                  minor=version_info.minor,\n",
    "                                                  micro=version_info.micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae00bc09-d73f-4b9e-9166-b6f9ad59b4b8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import cloudpickle\n",
    "conda_env = {\n",
    "    'channels': ['defaults'],\n",
    "    'dependencies': [\n",
    "      'python={}'.format(PYTHON_VERSION),\n",
    "      'pip',\n",
    "      {\n",
    "        'pip': [\n",
    "          'mlflow',\n",
    "          'transformers==4.28.1',\n",
    "          \"datasets==2.12.0\",\n",
    "          \"accelerate==0.18.0\",\n",
    "          \"bitsandbytes==0.40.0\",\n",
    "          'pandas',\n",
    "          \"sentencepiece\",\n",
    "          \"py7zr\",\n",
    "          'cloudpickle=={}'.format(cloudpickle.__version__),\n",
    "          'torch'],\n",
    "      },\n",
    "    ],\n",
    "    'name': 'dollyllamav2_environment'\n",
    "}\n",
    "\n",
    "mlflow_pyfunc_model_path = \"dollyllama7bv2_prod\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11d78562-7c62-4427-8397-095e07f4d6c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.pyfunc.log_model(artifact_path=mlflow_pyfunc_model_path, python_model=Dollyllama(),artifacts=artifacts, conda_env=conda_env, input_example = input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa0711cd-2694-4377-893d-c7d3e30b5c4c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Step 3_ Model Deployment",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
