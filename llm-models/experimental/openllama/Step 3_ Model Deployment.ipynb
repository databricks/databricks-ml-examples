{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d06c839a-4ce8-4a4b-b81b-b4fb332f59cb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.40.0.post3-py3-none-any.whl (101.8 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.8/101.8 MB 26.9 MB/s eta 0:00:00\nInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.40.0.post3\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: accelerate in /databricks/python3/lib/python3.10/site-packages (0.18.0)\nRequirement already satisfied: pyyaml in /databricks/python3/lib/python3.10/site-packages (from accelerate) (6.0)\nRequirement already satisfied: torch>=1.4.0 in /databricks/python3/lib/python3.10/site-packages (from accelerate) (1.13.1+cu117)\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: numpy>=1.17 in /databricks/python3/lib/python3.10/site-packages (from accelerate) (1.21.5)\nRequirement already satisfied: psutil in /databricks/python3/lib/python3.10/site-packages (from accelerate) (5.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /databricks/python3/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.0.9)\nRequirement already satisfied: typing-extensions in /databricks/python3/lib/python3.10/site-packages (from torch>=1.4.0->accelerate) (4.3.0)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting git+https://github.com/huggingface/peft.git\n  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-uk5k7mvx\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-uk5k7mvx\n  Resolved https://github.com/huggingface/peft.git to commit 4f542e319f5a164116946e999b197cc95f138567\n  Installing build dependencies: started\n  Installing build dependencies: finished with status 'done'\n  Getting requirements to build wheel: started\n  Getting requirements to build wheel: finished with status 'done'\n  Preparing metadata (pyproject.toml): started\n  Preparing metadata (pyproject.toml): finished with status 'done'\nRequirement already satisfied: accelerate in /databricks/python3/lib/python3.10/site-packages (from peft==0.4.0.dev0) (0.18.0)\nRequirement already satisfied: transformers in /databricks/python3/lib/python3.10/site-packages (from peft==0.4.0.dev0) (4.28.1)\nCollecting safetensors\n  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 9.6 MB/s eta 0:00:00\nRequirement already satisfied: torch>=1.13.0 in /databricks/python3/lib/python3.10/site-packages (from peft==0.4.0.dev0) (1.13.1+cu117)\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.10/site-packages (from peft==0.4.0.dev0) (21.3)\nRequirement already satisfied: psutil in /databricks/python3/lib/python3.10/site-packages (from peft==0.4.0.dev0) (5.9.0)\nRequirement already satisfied: numpy>=1.17 in /databricks/python3/lib/python3.10/site-packages (from peft==0.4.0.dev0) (1.21.5)\nRequirement already satisfied: pyyaml in /databricks/python3/lib/python3.10/site-packages (from peft==0.4.0.dev0) (6.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /databricks/python3/lib/python3.10/site-packages (from packaging>=20.0->peft==0.4.0.dev0) (3.0.9)\nRequirement already satisfied: typing-extensions in /databricks/python3/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0.dev0) (4.3.0)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.10/site-packages (from transformers->peft==0.4.0.dev0) (3.6.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /databricks/python3/lib/python3.10/site-packages (from transformers->peft==0.4.0.dev0) (0.14.1)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.10/site-packages (from transformers->peft==0.4.0.dev0) (2.28.1)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /databricks/python3/lib/python3.10/site-packages (from transformers->peft==0.4.0.dev0) (0.13.3)\nRequirement already satisfied: regex!=2019.12.17 in /databricks/python3/lib/python3.10/site-packages (from transformers->peft==0.4.0.dev0) (2022.7.9)\nRequirement already satisfied: tqdm>=4.27 in /databricks/python3/lib/python3.10/site-packages (from transformers->peft==0.4.0.dev0) (4.64.1)\nRequirement already satisfied: fsspec in /databricks/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers->peft==0.4.0.dev0) (2022.7.1)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests->transformers->peft==0.4.0.dev0) (3.3)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests->transformers->peft==0.4.0.dev0) (2.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests->transformers->peft==0.4.0.dev0) (2022.9.14)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests->transformers->peft==0.4.0.dev0) (1.26.11)\nBuilding wheels for collected packages: peft\n  Building wheel for peft (pyproject.toml): started\n  Building wheel for peft (pyproject.toml): finished with status 'done'\n  Created wheel for peft: filename=peft-0.4.0.dev0-py3-none-any.whl size=62233 sha256=a5d362a16dc44097544d0e23b6f835ab734c8021555d34f1677d4e7f30713020\n  Stored in directory: /tmp/pip-ephem-wheel-cache-zkk4xhl9/wheels/d7/c7/de/1368fac8590e1b103ddc2ec2a28ad51d83aded1a3830e8a087\nSuccessfully built peft\nInstalling collected packages: safetensors, peft\nSuccessfully installed peft-0.4.0.dev0 safetensors-0.3.1\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install bitsandbytes\n",
    "%pip install accelerate\n",
    "%pip install git+https://github.com/huggingface/peft.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85658232-793e-4a5f-aaa9-a5c855494f53",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ffb93a5f-af44-46b9-8aff-b26090c68b61",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Replace the path names based on where the adapters, model and tokenizers were saved during your work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bd220e1-079f-4205-85d5-f87bb50ef425",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "peft_model_id = \"/dbfs/FileStore/shared_uploads/<your-user-name>/dollyllama\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99a402a1-82ca-4a35-aac8-e9e1d8e30c45",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pretrained_model_id = 'openlm-research/open_llama_7b_v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81f0d773-e4fd-4c5d-80a2-794a7a6fd435",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a79fc21e-84c7-4601-94fd-86cff1d3f8f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37365ac2577147c086c000cb51b4efd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aee3e796a3243d0b8eb60eef12204a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)model.bin.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db5f5a824ea9427b9bc03dbe4c9416f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ec7e8470a54af78fd389d8b0d38e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00001-of-00002.bin:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0fb02ab7d034c81b385de695d70e012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00002-of-00002.bin:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563ab571e0b04433bfb466300496ecc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0953acbc10e54ff2bef1a8108f05b4cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    pretrained_model_id, device_map='auto',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59aa8ce8-7c78-4817-923e-71042dea216a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'openlm-research/open_llama_7b_v2'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "config.base_model_name_or_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "415fe516-d2ad-418d-ae40-b7bb554780f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "peft_model = PeftModel.from_pretrained(model, peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a3bb8e2-1c71-4adb-9f27-ebea0e91ef4e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "merged_model_path = \"/dbfs/FileStore/shared_uploads/<your-user-name>/dollyllama/merged_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "519eed8a-0335-4758-a177-222d7f76694b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "merged_model = peft_model.merge_and_unload()\n",
    "merged_model.save_pretrained(merged_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5aa1ce40-25f7-4b80-a16c-5c575aae6525",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "merged_model_tokenizer_path = \"/dbfs/FileStore/shared_uploads/<your-user-name>/dollyllama/merged_model_tokenizer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4608d2e4-0778-4ce5-b504-be35d819c3e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('/dbfs/FileStore/shared_uploads/avinash.sooriyarachchi@databricks.com/dollyllama/merged_model_tokenizer/tokenizer_config.json',\n",
       " '/dbfs/FileStore/shared_uploads/avinash.sooriyarachchi@databricks.com/dollyllama/merged_model_tokenizer/special_tokens_map.json',\n",
       " '/dbfs/FileStore/shared_uploads/avinash.sooriyarachchi@databricks.com/dollyllama/merged_model_tokenizer/tokenizer.model',\n",
       " '/dbfs/FileStore/shared_uploads/avinash.sooriyarachchi@databricks.com/dollyllama/merged_model_tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(merged_model_tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93f13490-853e-4194-abb8-18cdd9af1c05",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065f963974c04e59bcf2cd8f2f21017f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ensure that the final model can be loaded from the saved path\n",
    "model = LlamaForCausalLM.from_pretrained(merged_model_path, torch_dtype=torch.float16).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "539319d5-939b-4e79-b1a1-9d7923c08b07",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "java.lang.Exception: null\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.localLibraries$lzycompute(DriverLocal.scala:102)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.localLibraries(DriverLocal.scala:95)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.&lt;init&gt;(DriverLocal.scala:468)\n",
       "\tat com.databricks.backend.daemon.driver.PythonDriverLocalBase.&lt;init&gt;(PythonDriverLocalBase.scala:188)\n",
       "\tat com.databricks.backend.daemon.driver.JupyterDriverLocal.&lt;init&gt;(JupyterDriverLocal.scala:183)\n",
       "\tat com.databricks.backend.daemon.driver.PythonDriverWrapper.instantiateDriver(DriverWrapper.scala:869)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.setupRepl(DriverWrapper.scala:372)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:261)\n",
       "\tat java.lang.Thread.run(Thread.java:750)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "java.lang.Exception: null\n\tat com.databricks.backend.daemon.driver.DriverLocal.localLibraries$lzycompute(DriverLocal.scala:102)\n\tat com.databricks.backend.daemon.driver.DriverLocal.localLibraries(DriverLocal.scala:95)\n\tat com.databricks.backend.daemon.driver.DriverLocal.&lt;init&gt;(DriverLocal.scala:468)\n\tat com.databricks.backend.daemon.driver.PythonDriverLocalBase.&lt;init&gt;(PythonDriverLocalBase.scala:188)\n\tat com.databricks.backend.daemon.driver.JupyterDriverLocal.&lt;init&gt;(JupyterDriverLocal.scala:183)\n\tat com.databricks.backend.daemon.driver.PythonDriverWrapper.instantiateDriver(DriverWrapper.scala:869)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.setupRepl(DriverWrapper.scala:372)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:261)\n\tat java.lang.Thread.run(Thread.java:750)\n",
       "errorSummary": "Failure starting repl. Try detaching and re-attaching the notebook.\n\n",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "209746f2-2718-41da-b9c6-b22d56648b23",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Ensure that the tokenizer can be loaded from the saved path\n",
    "tokenizer = LlamaTokenizer.from_pretrained(merged_model_tokenizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32ec0054-d885-4084-91d2-432ca86645cd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Testing preprocessing and prediction functions before composing the pyfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fbfbd2b-2a4a-4ce6-9e1f-80e009c9ea20",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def build_prompt(instruction):\n",
    "    prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "  ### Instruction:\n",
    "  {}\n",
    "\n",
    "  ### Response:\n",
    "  \"\"\".format(instruction)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e095d0a1-ba3d-45a7-994e-07f086334b95",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def parse(text):\n",
    "    start_marker = '### Response:'\n",
    "    end_marker = '### End'\n",
    "    start_index = text.find(start_marker)\n",
    "    end_index = text.find(end_marker, start_index + len(start_marker))\n",
    "    \n",
    "    return (text[start_index + len(start_marker):].strip() if start_index != -1 and end_index == -1\n",
    "            else text[start_index + len(start_marker):end_index].strip() if start_index != -1\n",
    "            else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c45fda48-4213-4497-8391-973286e3b4ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def extract_response(text):\n",
    "    start_marker = '### Response:'\n",
    "    end_marker = '### End'\n",
    "    start_index = text.find(start_marker)\n",
    "    end_index = text.find(end_marker, start_index + len(start_marker))\n",
    "    \n",
    "    return (text[start_index + len(start_marker):].strip() if start_index != -1 and end_index == -1\n",
    "            else text[start_index + len(start_marker):end_index].strip() if start_index != -1\n",
    "            else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb8e99bc-dcab-4d40-88d4-79f207ae6363",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Explain how the US economy works using an analogy\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "# input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to('cuda')\n",
    "\n",
    "# generation_output = model.generate(\n",
    "#     input_ids=input_ids, max_new_tokens=128, penalty_alpha=0.5, top_k=4, \n",
    "# )\n",
    "# response = extract_response(tokenizer.decode(generation_output[0]))\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42d23fe3-1833-4e40-9158-2bc91c1c7f6f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Below is an instruction that describes a task...."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload_pd = pd.DataFrame([[prompt]],columns=['text'])\n",
    "payload_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "faf8d3eb-3073-41db-81ca-4e5641dffe46",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "input_example = payload_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4873b494-2d69-4734-bec8-70f1b6ed57cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def predict(model_input):\n",
    "    import json\n",
    "    question = model_input.iloc[:,0].to_list()[0] # get the first column\n",
    "    prompt = build_prompt(question)\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to('cuda')\n",
    "    generation_output = model.generate(\n",
    "    input_ids=input_ids[\"input_ids\"], max_new_tokens=128, penalty_alpha=0.5, top_k=4)\n",
    "    output = parse(tokenizer.decode(generation_output[0]))\n",
    "    result = {'response': output}\n",
    "    return json.dumps(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be9fcc15-f72e-4d48-81ae-e176b84210bf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'{\"response\": \"### Response:\\\\n  The US economy is like a car.  You have a driver (the government) who steers the car (the economy) in the direction they want to go.  There are tires (banks) that keep the car from going off the road, and there\\'s a gas pedal (consumers) that make the car go faster or slower.  If the driver doesn\\'t know where they want to go, they\\'ll drive around aimlessly, which is what we\\'ve been doing for the past 10 years.  If the driver is drunk, they\\'ll crash into a tree,\"}'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(input_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1c43dc2-9175-439b-82d9-301d2285b8cf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Log with MLFlow and Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd6f8d7f-1825-449d-8ce2-b6edc47e267f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "artifacts = {\n",
    "\"tokenizer_path\": merged_model_tokenizer_path,\n",
    "\"model_path\": merged_model_path,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec3eed58-52a3-43e6-89b5-9541098c7b0d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow.pyfunc\n",
    "\n",
    "class Dollyllama(mlflow.pyfunc.PythonModel):\n",
    "  def load_context(self, context):\n",
    "    from transformers import AutoModelForCausalLM\n",
    "    from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "    import torch\n",
    "    self.tokenizer = LlamaTokenizer.from_pretrained(context.artifacts['tokenizer_path'])\n",
    "    self.model = LlamaForCausalLM.from_pretrained(context.artifacts['model_path'], torch_dtype=torch.bfloat16)\n",
    "    self.model.to(device = \"cuda\")\n",
    "    self.model.eval()\n",
    "\n",
    "  def build_prompt(self, instruction):\n",
    "    prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "  ### Instruction:\n",
    "  {}\n",
    "\n",
    "  ### Response:\n",
    "  \"\"\".format(instruction)\n",
    "    return prompt\n",
    "\n",
    "  def parse(self, text):\n",
    "    start_marker = '### Response:'\n",
    "    end_marker = '### End'\n",
    "    start_index = text.find(start_marker)\n",
    "    end_index = text.find(end_marker, start_index + len(start_marker))\n",
    "    \n",
    "    return (text[start_index + len(start_marker):].strip() if start_index != -1 and end_index == -1\n",
    "            else text[start_index + len(start_marker):end_index].strip() if start_index != -1\n",
    "            else None)\n",
    "\n",
    "\n",
    "  def predict(self, context, model_input):\n",
    "    import json\n",
    "    question = model_input.iloc[:,0].to_list()[0] # get the first column\n",
    "    prompt = self.build_prompt(question)\n",
    "    input_ids = self.tokenizer(prompt, return_tensors=\"pt\").to('cuda')\n",
    "    generation_output = self.model.generate(\n",
    "    input_ids=input_ids[\"input_ids\"], max_new_tokens=180, penalty_alpha=0.5, top_k=4)\n",
    "    output = self.parse(self.tokenizer.decode(generation_output[0]))\n",
    "    result = {'response': output}\n",
    "    return json.dumps(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59de718a-13a5-4149-845e-cc7910e9b3de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sys import version_info\n",
    " \n",
    "PYTHON_VERSION = \"{major}.{minor}.{micro}\".format(major=version_info.major,\n",
    "                                                  minor=version_info.minor,\n",
    "                                                  micro=version_info.micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae00bc09-d73f-4b9e-9166-b6f9ad59b4b8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import cloudpickle\n",
    "conda_env = {\n",
    "    'channels': ['defaults'],\n",
    "    'dependencies': [\n",
    "      'python={}'.format(PYTHON_VERSION),\n",
    "      'pip',\n",
    "      {\n",
    "        'pip': [\n",
    "          'mlflow',\n",
    "          'transformers==4.28.1',\n",
    "          \"datasets==2.12.0\",\n",
    "          \"accelerate==0.18.0\",\n",
    "          \"bitsandbytes==0.40.0\",\n",
    "          'pandas',\n",
    "          \"sentencepiece\",\n",
    "          \"py7zr\",\n",
    "          'cloudpickle=={}'.format(cloudpickle.__version__),\n",
    "          'torch'],\n",
    "      },\n",
    "    ],\n",
    "    'name': 'dollyllamav2_environment'\n",
    "}\n",
    "\n",
    "mlflow_pyfunc_model_path = \"dollyllama7bv2_prod\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11d78562-7c62-4427-8397-095e07f4d6c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<mlflow.models.model.ModelInfo at 0x7f9ad43a1540>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.pyfunc.log_model(artifact_path=mlflow_pyfunc_model_path, python_model=Dollyllama(),artifacts=artifacts, conda_env=conda_env, input_example = input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa0711cd-2694-4377-893d-c7d3e30b5c4c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Step 3: Model Deployment",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
